# -*- coding: utf-8 -*-
"""AAT main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kun9qjFh7URPOr0XG1Q1FgY0XDzZ9jnE
"""

# !pip install mtcnn keras-facenet

import cv2 as cv
import os
import numpy as np
import time
from datetime import datetime
from sklearn.preprocessing import LabelEncoder
from mtcnn.mtcnn import MTCNN
from keras_facenet import FaceNet
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import pickle
model = pickle.load(open('svm_model_160x160.pkl', 'rb'))

encoder = LabelEncoder()
encoder.classes_ = np.load('encoder.npy')

embedder = FaceNet()

def get_embedding(face_img):
  """
  Generates a facial embedding for a single face image.

  Args:
      face_img: A NumPy array of shape (160, 160, 3) representing a preprocessed face image in RGB format.

  Returns:
      A NumPy array of shape (512,) containing the facial embedding for the given face.
  """
  # Assuming you have an embedding model (`embedder`) defined elsewhere
  # Convert data type to float32 for potential model requirements
  face_img = face_img.astype('float32')
  # Ensure the image has the expected shape (1, 160, 160, 3)
  face_img = np.expand_dims(face_img, axis=0)
  embedding = embedder.embeddings(face_img)
  return embedding[0]  # Return the first embedding (assuming one face)

def face_detection(image_path):
  """
  Detects faces in an image using MTCNN.

  Args:
      image_path: Path to the image file.

  Returns:
      A tuple containing:
          - The original image (`t_im`)
          - A list of detected faces (`faces`), where each face is a dictionary with bounding box coordinates (`x`, `y`, `w`, `h`).
  """
  t_im = cv.imread(image_path)
  t_im = cv.cvtColor(t_im, cv.COLOR_BGR2RGB)  # Convert to RGB for MTCNN

  detector = MTCNN()
  results = detector.detect_faces(t_im)
  faces = []
  for i in results:
    if i['confidence'] > 0.999:
      faces.append(i)
  return t_im, faces


def face_embedder(image_path):
    embeddings = []
    t_im, faces = face_detection(image_path)
    for i in faces:
      x,y,w,h = i['box']
      # print(x,y,w,h)
      t_im1 = t_im[y:y+h, x:x+w]
      # print(t_im1.size)

      t_im1 = cv.resize(t_im1, (160,160))
      test_im = get_embedding(t_im1)
      test_im = [test_im]
      embeddings.append(test_im)
    return embeddings


def predictor(image_path):
  Attendance = []
  embeddings = face_embedder(image_path)
  # Flatten the list of embeddings into a single array
  embeddings_array = np.concatenate(embeddings)
  # Reshape the array to 2D if necessary (depends on your model's expected input shape)
  # For example, if your model expects a 2D array with shape (n_samples, n_features), you might need to reshape
  # embeddings_array = embeddings_array.reshape(-1, 512)  # Adjust based on your model's requirements
  yprobs = model.predict_proba(embeddings_array)


  ypreds = model.predict(embeddings_array)
  for i in range(len(ypreds)):
  # print(i,j)
    if yprobs[i][ypreds[i]] > 0.2:
      Attendance.append(encoder.inverse_transform(ypreds)[i])
  # if yprobs[0][ypreds[0]] > 0.28:
  #   Attendance.append(encoder.inverse_transform(ypreds)[0])
  return Attendance

  # return Attendance


# # Example usage
# t0 = time.time()
# image_path = '/content/IMG-20240504-WA0037.jpg'  # Replace with your image path
# Attendance = predictor(image_path)
# t1 = time.time()
# print(t1-t0)
# print(Attendance)

